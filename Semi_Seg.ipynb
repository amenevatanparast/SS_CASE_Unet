{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29267,"status":"ok","timestamp":1750951986499,"user":{"displayName":"Amina_ Vtn","userId":"14456474243033549957"},"user_tz":-240},"id":"oJr06zxsmnNJ","outputId":"19ce95ba-0683-4a47-e402-e85c5b97c40e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rz4ZekjA7zUu"},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from IPython.display import clear_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9MlE5zd7zXo"},"outputs":[],"source":["# --- 0. Configuration and Setup ---\n","IMG_WIDTH = 256\n","IMG_HEIGHT = 256\n","NUM_CLASSES = 1\n","BATCH_SIZE = 8\n","EPOCHS_DECODER_TRAINING = 1\n","EPOCHS_FULL_FINE_TUNE = 1\n","EPOCHS_PSEUDO_LABELING_TRAINING = 1\n","LEARNING_RATE_DECODER = 1e-4\n","LEARNING_RATE_FINE_TUNE = 1e-5\n","LEARNING_RATE_PSEUDO_LABELING = 5e-6\n","\n","PSEUDO_LABEL_CONFIDENCE_THRESHOLD = 0.95\n","PSEUDO_LABEL_MIN_MASK_PIXELS = 10\n","\n","DATA_DIR = '/content/drive/MyDrive/Colab/PHD/Cerebellar/data_cell_new_200'\n","LABELED_IMAGES_DIR = os.path.join(DATA_DIR, 'image')\n","LABELED_MASKS_DIR = os.path.join(DATA_DIR, 'ground_truth')\n","UNLABELED_IMAGES_DIR = os.path.join('/content/drive/MyDrive/Colab/PHD/Cerebellar/Unlabeled')\n","\n","os.makedirs(LABELED_IMAGES_DIR, exist_ok=True)\n","os.makedirs(LABELED_MASKS_DIR, exist_ok=True)\n","os.makedirs(UNLABELED_IMAGES_DIR, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"turA56Fq7zaj"},"outputs":[],"source":["# --- 1. Data Loading and Preprocessing Functions ---\n","\n","def load_image_and_mask(image_path, mask_path, target_size=(IMG_WIDTH, IMG_HEIGHT)):\n","\n","    image = cv2.imread(image_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = cv2.resize(image, target_size)\n","    image = image.astype(np.float32) / 255.0\n","\n","    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","    mask = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n","    mask = np.expand_dims(mask, axis=-1)\n","    mask = (mask > 0).astype(np.float32)\n","\n","    return image, mask\n","\n","def load_dataset(image_dir, mask_dir):\n","    image_filenames = sorted([f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n","    images = []\n","    masks = []\n","\n","    for img_name in image_filenames:\n","        base_name, ext = os.path.splitext(img_name)\n","        expected_mask_name = f\"{base_name}_G{ext}\"\n","        mask_path = os.path.join(mask_dir, expected_mask_name)\n","        image_path = os.path.join(image_dir, img_name)\n","\n","        if os.path.exists(mask_path):\n","            img, msk = load_image_and_mask(image_path, mask_path)\n","            images.append(img)\n","            masks.append(msk)\n","        else:\n","            print(f\"Warning: No mask found for {img_name} at {mask_path}. Skipping this pair.\")\n","\n","    if not images:\n","        raise ValueError(\"No matching image/mask pairs found with the '_G' suffix convention. Please check your filenames.\")\n","    return np.array(images), np.array(masks)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"G88wVEjq7zdZ","outputId":"a8f6c3de-8ec4-4d6a-967d-fcd53afbb626"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded 200 labeled images and masks.\n","Loaded 51 unlabeled images.\n","Training on 150 images, validating on 10 images, testing on 40 images.\n"]}],"source":["# Load your labeled data (200 images).\n","#print(f\"Loading labeled data from: {LABELED_IMAGES_DIR} and {LABELED_MASKS_DIR}\")\n","try:\n","    X_labeled, y_labeled = load_dataset(LABELED_IMAGES_DIR, LABELED_MASKS_DIR)\n","    print(f\"Loaded {len(X_labeled)} labeled images and masks.\")\n","    if len(X_labeled) == 0:\n","        raise ValueError(\"No labeled data found. Please ensure your 'fetal_brain_data/labeled/images' and 'fetal_brain_data/labeled/masks' directories contain images and corresponding masks.\")\n","except Exception as e:\n","    print(f\"Error loading labeled data: {e}\")\n","    print(\"Please ensure your data is organized as specified and filenames match.\")\n","    pass\n","\n","\n","# Load unlabeled images\n","#print(f\"Loading unlabeled data from: {UNLABELED_IMAGES_DIR}\")\n","try:\n","    unlabeled_image_filenames = sorted([f for f in os.listdir(UNLABELED_IMAGES_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n","    X_unlabeled = []\n","    for img_name in unlabeled_image_filenames:\n","        img_path = os.path.join(UNLABELED_IMAGES_DIR, img_name)\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n","        image = image.astype(np.float32) / 255.0\n","        X_unlabeled.append(image)\n","    X_unlabeled = np.array(X_unlabeled)\n","    print(f\"Loaded {len(X_unlabeled)} unlabeled images.\")\n","except Exception as e:\n","    print(f\"Error loading unlabeled data: {e}\")\n","    print(\"Please ensure your 'Unlabeled' directory contains images.\")\n","    X_unlabeled = np.array([])\n","\n","\n","\n","if len(X_labeled) > 0:\n","    X_train, X_val_, y_train, y_val_ = train_test_split(X_labeled, y_labeled, test_size=0.25, random_state=42)\n","    X_test, X_val, y_test, y_val = train_test_split(X_val_, y_val_, test_size=0.2, random_state=42)\n","    print(f\"Training on {len(X_train)} images, validating on {len(X_val)} images, testing on {len(X_test)} images.\")\n","else:\n","    print(\"Skipping data split as no labeled data was loaded.\")\n","    X_train, X_val, y_train, y_val = np.array([]), np.array([]), np.array([]), np.array([])\n","    X_test, y_test = np.array([]), np.array([])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EwvNOwXp7zgD"},"outputs":[],"source":["# --- 2. Build the U-Net Model ---\n","\"\"\"\n","def unet_model(input_size=(IMG_WIDTH, IMG_HEIGHT, 3), num_classes=1, backbone='resnet50'):\n","    inputs = keras.Input(input_size)\n","\n","    # Encoder\n","    if backbone == 'resnet50':\n","        base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n","        skip_connections = [\n","            base_model.get_layer('conv1_relu').output,    # After initial conv (high resolution)\n","            base_model.get_layer('conv2_block3_out').output, # After block 2\n","            base_model.get_layer('conv3_block4_out').output, # After block 3\n","            base_model.get_layer('conv4_block6_out').output, # After block 4 (lowest resolution before bottleneck)\n","        ]\n","        bottleneck = base_model.get_layer('conv5_block3_out').output\n","\n","    elif backbone == 'efficientnetb0':\n","        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_tensor=inputs)\n","        # Define skip connection layers for EfficientNetB0.\n","        skip_connections = [\n","            base_model.get_layer('block2a_expand_activation').output,\n","            base_model.get_layer('block3a_expand_activation').output,\n","            base_model.get_layer('block4a_expand_activation').output,\n","            base_model.get_layer('block5a_expand_activation').output,\n","        ]\n","        bottleneck = base_model.get_layer('top_activation').output\n","\n","    else:\n","        raise ValueError(\"Unsupported backbone. Choose 'resnet50' or 'efficientnetb0'.\")\n","\n","    # Decoder (Upsampling Path)\n","    x = bottleneck\n","    skip_connections.reverse()\n","\n","    for i, skip_feature in enumerate(skip_connections):\n","        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n","        x = layers.Concatenate()([x, skip_feature])\n","        filters = max(32, 256 // (2**i))\n","        x = layers.Conv2D(filters, 3, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n","        x = layers.Conv2D(filters, 3, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n","        x = layers.Dropout(0.3)(x)\n","    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n","    x = layers.Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n","    x = layers.Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n","    x = layers.Dropout(0.2)(x)\n","\n","    if num_classes == 1:\n","        outputs = layers.Conv2D(1, 1, activation='sigmoid')(x)\n","    else:\n","        outputs = layers.Conv2D(num_classes, 1, activation='softmax')(x)\n","\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    return model\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dltU7DlsIODD"},"outputs":[],"source":["from tensorflow.keras import backend as K\n","from tensorflow.keras import layers\n","import tensorflow as tf\n","# --- 2. Build the Novel U-Net Model (CoSE-U-Net) ---\n","\n","# Squeeze-and-Excitation (SE) Block\n","\n","\n","def se_block(input_feature, ratio=32):\n","    filters = K.int_shape(input_feature)[-1]\n","    assert filters is not None, \"Channel dimension must be defined.\"\n","    se = layers.GlobalAveragePooling2D()(input_feature)  # (None, filters)\n","    se = layers.Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n","    se = layers.Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n","    se = layers.Lambda(lambda s: tf.expand_dims(tf.expand_dims(s, axis=1), axis=1))(se)  # (None, 1, 1, filters)\n","    x = layers.Multiply()([input_feature, se])\n","    return x\n","\n","def coord_attention_block(x):\n","\n","    filters = x.shape[-1]\n","    assert filters is not None, \"The channel dimension must be defined.\"\n","    reduced_filters = max(8, filters // 32)\n","\n","    # Height-wise pooling: (B, H, 1, C)\n","    pool_h = layers.Lambda(lambda x: tf.reduce_mean(x, axis=2, keepdims=True))(x)\n","\n","    # Width-wise pooling: (B, 1, W, C)\n","    pool_w = layers.Lambda(lambda x: tf.reduce_mean(x, axis=1, keepdims=True))(x)\n","    pool_w = layers.Lambda(lambda x: tf.transpose(x, [0, 2, 1, 3]))(pool_w)  # (B, W, 1, C)\n","\n","    # Concatenate along height and width (axis=1)\n","    concat = layers.Concatenate(axis=1)([pool_h, pool_w])  # (B, H+W, 1, C)\n","\n","    # Shared transformation\n","    shared = layers.Conv2D(reduced_filters, kernel_size=1, activation='relu', padding='same')(concat)\n","    shared = layers.BatchNormalization()(shared)\n","\n","    # Split into height and width parts\n","    split_h, split_w = layers.Lambda(lambda t: tf.split(t, num_or_size_splits=2, axis=1))(shared)\n","    split_w = layers.Lambda(lambda t: tf.transpose(t, [0, 2, 1, 3]))(split_w)\n","\n","    # Attention maps\n","    attn_h = layers.Conv2D(filters, kernel_size=1, activation='sigmoid', padding='same')(split_h)\n","    attn_w = layers.Conv2D(filters, kernel_size=1, activation='sigmoid', padding='same')(split_w)\n","\n","    # Apply both attentions\n","    out = layers.Multiply()([x, attn_h, attn_w])\n","    return out\n","\n","\n","def unet_model(input_size=(256, 256, 3), num_classes=1, backbone='resnet50'):\n","\n","    inputs = keras.Input(input_size)\n","\n","\n","    # Encoder (Downsampling Path) using a pre-trained backbone\n","    if backbone == 'resnet50':\n","        base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n","\n","        # Collect outputs for skip connections and apply SE blocks\n","        s1 = base_model.get_layer('conv1_relu').output\n","        s1 = se_block(s1) # Apply SE to skip connection feature\n","\n","        s2 = base_model.get_layer('conv2_block3_out').output\n","        s2 = se_block(s2) # Apply SE to skip connection feature\n","\n","        s3 = base_model.get_layer('conv3_block4_out').output\n","        s3 = se_block(s3) # Apply SE to skip connection feature\n","\n","        s4 = base_model.get_layer('conv4_block6_out').output\n","        s4 = se_block(s4) # Apply SE to skip connection feature\n","\n","        # The bottleneck feature\n","        bottleneck = base_model.get_layer('conv5_block3_out').output\n","\n","        # Apply Coordinate Attention to the bottleneck\n","        bottleneck = coord_attention_block(bottleneck)\n","\n","        skip_connections = [s1, s2, s3, s4] # Collect SE-enhanced skip features\n","\n","\n","    elif backbone == 'efficientnetb0':\n","        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_tensor=inputs)\n","\n","\n","        # Collect outputs for skip connections and apply SE blocks\n","        s1 = base_model.get_layer('block2a_expand_activation').output\n","        s1 = se_block(s1)\n","\n","        s2 = base_model.get_layer('block3a_expand_activation').output\n","        s2 = se_block(s2)\n","\n","        s3 = base_model.get_layer('block4a_expand_activation').output\n","        s3 = se_block(s3)\n","\n","        s4 = base_model.get_layer('block5a_expand_activation').output\n","        s4 = se_block(s4)\n","\n","        # Bottleneck for EfficientNetB0.\n","        bottleneck = base_model.get_layer('top_activation').output\n","        bottleneck = coord_attention_block(bottleneck)\n","        skip_connections = [s1, s2, s3, s4]\n","\n","\n","    else:\n","        raise ValueError(\"Unsupported backbone. Choose 'resnet50' or 'efficientnetb0'.\")\n","\n","    # Decoder (Upsampling Path)\n","    x = bottleneck\n","\n","    # Iterate through skip connections in reverse order (from deepest to shallowest encoder features).\n","    # This matches the U-Net's expansive path.\n","    skip_connections.reverse()\n","\n","    for i, skip_feature in enumerate(skip_connections):\n","        # Bilinear upsampling\n","        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n","        x = layers.Concatenate()([x, skip_feature])\n","\n","        # Use a slightly smaller filter count in the decoder as we go up\n","        filters = max(16, 128 // (2**i))\n","        x = layers.Conv2D(filters, 3, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n","        x = layers.Conv2D(filters, 3, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n","        x = layers.Dropout(0.3)(x)\n","        x = se_block(x)\n","\n","\n","    # Final upsampling block to match the target resolution (256x256)\n","    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n","    x = layers.Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n","    x = layers.Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n","    x = layers.Dropout(0.2)(x)\n","\n","\n","    # Output layer for segmentation.\n","    if num_classes == 1:\n","        outputs = layers.Conv2D(1, 1, activation='sigmoid')(x)\n","    else:\n","        outputs = layers.Conv2D(num_classes, 1, activation='softmax')(x)\n","\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4_TfqJQ7zis"},"outputs":[],"source":["# --- 3. Define Loss Functions and Metrics ---\n","\n","def dice_coeff(y_true, y_pred):\n","    smooth = 1e-6\n","    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n","    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n","\n","def dice_loss(y_true, y_pred):\n","    return 1.0 - dice_coeff(y_true, y_pred)\n","\n","def bce_dice_loss(y_true, y_pred):\n","    bce_loss = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n","    dice = dice_loss(y_true, y_pred)\n","    return 0.5 * bce_loss + 0.5 * dice\n","\n","#-------------------------------------------------------------------------------\n","#-------------------------------------------------------------------------------\n","#-------------------------------------------------------------------------------\n","#-------------------------------------------------------------------------------\n","#MERTICS\n","\n","def jaccard_index(y_true, y_pred, smooth=1e-6):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n","    return (intersection + smooth) / (union + smooth)\n","\n","def dice_coefficient(y_true, y_pred, smooth=1e-6):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","# Precision\n","def precision_metric(y_true, y_pred, smooth=1e-6):\n","    y_pred_bin = K.round(K.clip(y_pred, 0, 1))\n","    y_true_bin = K.round(K.clip(y_true, 0, 1))\n","    true_positives = K.sum(y_true_bin * y_pred_bin)\n","    predicted_positives = K.sum(y_pred_bin)\n","    return (true_positives + smooth) / (predicted_positives + smooth)\n","\n","# Recall\n","def recall_metric(y_true, y_pred, smooth=1e-6):\n","    y_pred_bin = K.round(K.clip(y_pred, 0, 1))\n","    y_true_bin = K.round(K.clip(y_true, 0, 1))\n","    true_positives = K.sum(y_true_bin * y_pred_bin)\n","    possible_positives = K.sum(y_true_bin)\n","    return (true_positives + smooth) / (possible_positives + smooth)\n","\n","# Accuracy\n","def accuracy_metric(y_true, y_pred):\n","    y_pred_bin = K.round(K.clip(y_pred, 0, 1))\n","    y_true_bin = K.round(K.clip(y_true, 0, 1))\n","    return K.mean(K.equal(y_true_bin, y_pred_bin))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2ZRYo4Du7zlQ"},"outputs":[],"source":["# --- 4. Model Instantiation and Training Stages ---\n","\n","model = unet_model(backbone='efficientnetb0')\n","model.summary()\n","\n","# Freeze the base model (encoder) layers.\n","if isinstance(model.layers[1], tf.keras.Model):\n","    print(f\"Freezing base model (encoder): {model.layers[1].name}\")\n","    model.layers[1].trainable = False\n","else:\n","    print(\"Manually freezing backbone layers (assuming ResNet/EfficientNet naming conventions)...\")\n","    for layer in model.layers:\n","        if 'res' in layer.name or 'conv' in layer.name and layer.name.startswith('conv'): # General ResNet layers\n","            layer.trainable = False\n","        if 'efficientnet' in layer.name:\n","            layer.trainable = False\n","\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE_DECODER),\n","              loss=bce_dice_loss, metrics=[jaccard_index, dice_coefficient, precision_metric,\n","              recall_metric, accuracy_metric])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UWtuwRJRP_wG"},"outputs":[],"source":["def apply_paper_augmentation(image, mask):\n","    augmented_images = []\n","    augmented_masks = []\n","    img_uint8 = (image * 255).astype(np.uint8)\n","    img_gray = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)\n","\n","    # 1. Noise Removal on Image\n","    img_denoised_gray = cv2.medianBlur(img_gray, 5)\n","    img_denoised_rgb = cv2.cvtColor(img_denoised_gray, cv2.COLOR_GRAY2RGB).astype(np.float32) / 255.0\n","    mask_uint8 = (mask * 255).astype(np.uint8)\n","    kernel_small = np.ones((3,3), np.uint8)\n","    kernel_large = np.ones((5,5), np.uint8)\n","\n","    # 2. Morphological Operations on Mask (4 types * 2 kernel sizes = 8 variations)\n","    morph_ops = {\n","        \"dilate\": cv2.MORPH_DILATE,\n","        \"erode\": cv2.MORPH_ERODE,\n","        \"open\": cv2.MORPH_OPEN, # Opening = erosion followed by dilation\n","        \"close\": cv2.MORPH_CLOSE # Closing = dilation followed by erosion\n","    }\n","    kernels = {\"small\": kernel_small, \"large\": kernel_large}\n","\n","    base_augmented_pairs = []\n","    for op_name, op_code in morph_ops.items():\n","        for kernel_name, kernel in kernels.items():\n","            if op_name == \"dilate\":\n","                transformed_mask = cv2.dilate(mask_uint8, kernel, iterations=1)\n","            elif op_name == \"erode\":\n","                transformed_mask = cv2.erode(mask_uint8, kernel, iterations=1)\n","            else:\n","                transformed_mask = cv2.morphologyEx(mask_uint8, op_code, kernel)\n","            transformed_mask = np.expand_dims(transformed_mask.astype(np.float32) / 255.0, axis=-1)\n","            base_augmented_pairs.append((img_denoised_rgb, transformed_mask))\n","\n","    #  Add Zoom and Flips to each base_augmented_pair\n","    zoom_scale = 1.2\n","    h, w, c = img_denoised_rgb.shape\n","\n","    for base_img, base_mask in base_augmented_pairs:\n","        # 1. Original Scale (no zoom, no flip)\n","        augmented_images.append(base_img)\n","        augmented_masks.append(base_mask)\n","\n","        # 2. Zoomed Version\n","        new_h, new_w = int(h * zoom_scale), int(w * zoom_scale)\n","\n","        # Resize (zoom in)\n","        zoomed_img = cv2.resize(base_img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n","        zoomed_mask = cv2.resize(base_mask, (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n","        if zoomed_mask.ndim == 2:\n","            zoomed_mask = np.expand_dims(zoomed_mask, axis=-1)\n","\n","        # Crop back to original size from the center\n","        start_h = (new_h - h) // 2\n","        start_w = (new_w - w) // 2\n","        cropped_zoomed_img = zoomed_img[start_h:start_h+h, start_w:start_w+w, :]\n","        cropped_zoomed_mask = zoomed_mask[start_h:start_h+h, start_w:start_w+w, :] # This line will now work\n","\n","        # Ensure cropped_zoomed_mask is binary and has channel dim\n","        cropped_zoomed_mask = (cropped_zoomed_mask > 0.5).astype(np.float32)\n","        if cropped_zoomed_mask.ndim == 2:\n","            cropped_zoomed_mask = np.expand_dims(cropped_zoomed_mask, axis=-1)\n","        augmented_images.append(np.fliplr(base_img).astype(np.float32))\n","        flipped_base_mask_lr = np.fliplr(base_mask).astype(np.float32)\n","        if flipped_base_mask_lr.ndim == 2:\n","            flipped_base_mask_lr = np.expand_dims(flipped_base_mask_lr, axis=-1)\n","        augmented_masks.append(flipped_base_mask_lr)\n","\n","        augmented_images.append(np.flipud(base_img).astype(np.float32))\n","        flipped_base_mask_ud = np.flipud(base_mask).astype(np.float32)\n","        if flipped_base_mask_ud.ndim == 2:\n","            flipped_base_mask_ud = np.expand_dims(flipped_base_mask_ud, axis=-1)\n","        augmented_masks.append(flipped_base_mask_ud)\n","\n","        augmented_images.append(cropped_zoomed_img)\n","        augmented_masks.append(cropped_zoomed_mask)\n","\n","        # 3. Horizontal Flip (original scale)\n","        augmented_images.append(np.fliplr(base_img).astype(np.float32))\n","        augmented_masks.append(np.fliplr(base_mask).astype(np.float32))\n","\n","        # 4. Vertical Flip (original scale)\n","        augmented_images.append(np.flipud(base_img).astype(np.float32))\n","        augmented_masks.append(np.flipud(base_mask).astype(np.float32))\n","\n","    return augmented_images, augmented_masks, img_denoised_rgb # Return denoised image too\n","\n","\n","def train_generator(images, masks, batch_size):\n","    num_samples = len(images)\n","    while True:\n","        indices = np.random.permutation(num_samples)\n","        total_augmented_samples_per_epoch = num_samples * 32\n","\n","        yielded_samples = 0\n","        current_batch_images = []\n","        current_batch_masks = []\n","\n","        for i in range(num_samples): # Iterate through original samples\n","            original_idx = indices[i]\n","            current_image = images[original_idx]\n","            current_mask = masks[original_idx]\n","\n","            # Apply paper-specific augmentation (now includes flips and zoom)\n","            aug_imgs, aug_msks, _ = apply_paper_augmentation(current_image, current_mask)\n","\n","            for aug_img, aug_msk in zip(aug_imgs, aug_msks):\n","                current_batch_images.append(aug_img)\n","                current_batch_masks.append(aug_msk)\n","\n","                if len(current_batch_images) == batch_size:\n","                    yield np.array(current_batch_images), np.array(current_batch_masks)\n","                    yielded_samples += batch_size\n","                    current_batch_images = []\n","                    current_batch_masks = []\n","\n","        # Yield any remaining samples in the last partial batch\n","        if current_batch_images:\n","            yield np.array(current_batch_images), np.array(current_batch_masks)\n","            yielded_samples += len(current_batch_images)\n","\n","        # Print the total number of augmented images generated per epoch\n","        print(f\"\\nTotal augmented images generated per epoch: {total_augmented_samples_per_epoch}\")\n","\n","train_gen = train_generator(X_train, y_train, BATCH_SIZE)\n","val_gen = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n","if len(X_train) > 0:\n","    steps_per_epoch_stage1 = (len(X_train) * 32) // BATCH_SIZE\n","    if (len(X_train) * 32) % BATCH_SIZE != 0:\n","        steps_per_epoch_stage1 += 1\n","else:\n","    steps_per_epoch_stage1 = 0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gotv5q6lRk46"},"outputs":[],"source":["# --- Stage 1: Train only the decoder (freeze encoder) ---\n","print(\"\\n--- Stage 1: Training Decoder (Encoder Frozen) ---\")\n","\n","if len(X_train) > 0:\n","    history_decoder = model.fit(\n","        train_gen,\n","        steps_per_epoch=steps_per_epoch_stage1, # Number of batches per epoch\n","        epochs=EPOCHS_DECODER_TRAINING,\n","        validation_data=val_gen,\n","        callbacks=[\n","            keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True, monitor='val_loss'),\n","            keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2, min_lr=1e-7, verbose=1, monitor='val_loss') ]\n","    )\n","else:\n","    print(\"Skipping Stage 1 training as no training data is available.\")\n","    history_decoder = None # Initialize history as None if no training\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8e9vz7FcRbSN"},"outputs":[],"source":["def generate_pseudo_labels(model_to_predict, unlabeled_images, confidence_threshold, min_mask_pixels):\n","    if len(unlabeled_images) == 0:\n","        print(\"No unlabeled images to generate pseudo-labels for.\")\n","        return np.array([]), np.array([])\n","\n","    print(f\"\\nGenerating predictions for {len(unlabeled_images)} unlabeled images...\")\n","    # Predict raw probability maps for all unlabeled images\n","    raw_predictions = model_to_predict.predict(unlabeled_images, batch_size=BATCH_SIZE*2, verbose=1)\n","\n","    pseudo_labeled_images = []\n","    pseudo_labeled_masks = []\n","    num_confident_masks = 0\n","\n","    print(f\"Filtering pseudo-labels with confidence threshold > {confidence_threshold} and min_mask_pixels > {min_mask_pixels}...\")\n","    for i in range(len(unlabeled_images)):\n","        prob_map = raw_predictions[i].squeeze() # Remove channel dim\n","        pseudo_mask = (prob_map > 0.5).astype(np.float32)\n","        confident_fg_pixels = np.sum(prob_map >= confidence_threshold)\n","        confident_bg_pixels = np.sum(prob_map <= (1.0 - confidence_threshold))\n","        total_pixels = prob_map.size\n","\n","        confident_pixel_percentage = (confident_fg_pixels + confident_bg_pixels) / total_pixels\n","\n","        if confident_pixel_percentage > 0.9 and np.sum(pseudo_mask) >= min_mask_pixels: # Require 90% confident pixels AND a non-tiny mask\n","            pseudo_labeled_images.append(unlabeled_images[i])\n","            pseudo_labeled_masks.append(np.expand_dims(pseudo_mask, axis=-1)) # Add channel dim back\n","            num_confident_masks += 1\n","\n","\n","    print(f\"Generated {num_confident_masks} confident pseudo-labeled samples out of {len(unlabeled_images)} unlabeled images.\")\n","    return np.array(pseudo_labeled_images), np.array(pseudo_labeled_masks)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mn6O-rdl5i_g"},"outputs":[],"source":["# --- Stage 2: Fine-tune the entire network ---\n","print(\"\\n--- Stage 2: Fine-tuning Full Network (All Layers Unfrozen) ---\")\n","\n","for layer in model.layers:\n","    layer.trainable = True\n","\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE_FINE_TUNE),\n","              loss=bce_dice_loss,\n","              metrics=[jaccard_index, dice_coefficient, precision_metric,\n","        recall_metric, accuracy_metric])\n","\n","if len(X_train) > 0:\n","    steps_per_epoch_stage2 = (len(X_train) * 32) // BATCH_SIZE\n","    if (len(X_train) * 32) % BATCH_SIZE != 0:\n","        steps_per_epoch_stage2 += 1\n","else:\n","    steps_per_epoch_stage2 = 0\n","\n","# Train the model for Stage 2 (full network fine-tuning).\n","if len(X_train) > 0:\n","    history_full = model.fit(\n","        train_gen, # Continues to use X_train from Stage 1 for training\n","        steps_per_epoch=steps_per_epoch_stage2,\n","        epochs=EPOCHS_FULL_FINE_TUNE,\n","        validation_data=val_gen,\n","        callbacks=[\n","            # Early stopping with more patience for full fine-tuning.\n","            # --- FIX: Increased patience slightly for observation ---\n","            keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss'), # Increased from 10 to 15\n","            # Reduce learning rate when validation loss plateaus.\n","            keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-8, verbose=1, monitor='val_loss')\n","        ]\n","    )\n","else:\n","    print(\"Skipping Stage 2 training as no training data is available.\")\n","    history_full = None # Initialize history as None if no training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMJTYrp2Dh-Q"},"outputs":[],"source":["# --- NEW: Stage 3: Pseudo-labeling and Re-training on Combined Data ---\n","print(\"\\n--- Stage 3: Pseudo-labeling and Re-training on Combined Data ---\")\n","\n","if len(X_unlabeled) > 0 and len(X_train) > 0:\n","    pseudo_images, pseudo_masks = generate_pseudo_labels(\n","        model, X_unlabeled, PSEUDO_LABEL_CONFIDENCE_THRESHOLD, PSEUDO_LABEL_MIN_MASK_PIXELS\n","    )\n","\n","    if len(pseudo_images) > 0:\n","        X_labeled_for_pseudo_training = np.concatenate((X_train, X_test), axis=0) # Use all 190 labeled images\n","        y_labeled_for_pseudo_training = np.concatenate((y_train, y_test), axis=0) # Use all 190 labeled masks\n","\n","        X_combined_train_pseudo = np.concatenate((X_labeled_for_pseudo_training, pseudo_images), axis=0)\n","        y_combined_train_pseudo = np.concatenate((y_labeled_for_pseudo_training, pseudo_masks), axis=0)\n","        print(f\"Combined training data size for Stage 3: {len(X_combined_train_pseudo)} (Original Labeled: {len(X_labeled_for_pseudo_training)}, Pseudo: {len(pseudo_images)})\")\n","\n","        # Re-compile the model for Stage 3 with a very small learning rate\n","        model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE_PSEUDO_LABELING),\n","                      loss=bce_dice_loss,\n","                      metrics=[jaccard_index, dice_coefficient, precision_metric,\n","                      recall_metric, accuracy_metric])\n","\n","        # Create a new generator for the combined dataset (with custom aug again)\n","        combined_train_gen_pseudo = train_generator(\n","            X_combined_train_pseudo, y_combined_train_pseudo, BATCH_SIZE\n","        )\n","\n","        # Calculate steps_per_epoch for Stage 3\n","        steps_per_epoch_stage3 = (len(X_combined_train_pseudo) * 32) // BATCH_SIZE # *32 for augmentation\n","        if (len(X_combined_train_pseudo) * 32) % BATCH_SIZE != 0:\n","            steps_per_epoch_stage3 += 1\n","\n","        print(f\"Starting Stage 3 training on combined data for {EPOCHS_PSEUDO_LABELING_TRAINING} epochs...\")\n","        history_pseudo_labeling = model.fit(\n","            combined_train_gen_pseudo,\n","            steps_per_epoch=steps_per_epoch_stage3,\n","            epochs=EPOCHS_PSEUDO_LABELING_TRAINING,\n","            validation_data=val_gen, # Still validate on the original held-out validation set (X_val, y_val)\n","            callbacks=[\n","                keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True, monitor='val_loss'), # More patience\n","                keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-9, verbose=1, monitor='val_loss')\n","            ]\n","        )\n","        print(\"\\nStage 3: Pseudo-labeling training complete!\")\n","    else:\n","        print(\"No confident pseudo-labels generated. Skipping Stage 3 training.\")\n","        history_pseudo_labeling = None\n","else:\n","    print(\"Not enough unlabeled or labeled data to perform pseudo-labeling. Skipping Stage 3 training.\")\n","    history_pseudo_labeling = None\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Nf1JYHcqKRf"},"outputs":[],"source":["test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n","evaluation_results = model.evaluate(test_dataset)\n","(\n","    test_loss,\n","    test_jaccard,\n","    test_dice,\n","    test_precision,\n","    test_recall,\n","    test_accuracy\n",") = evaluation_results\n","\n","print(f\"Test Loss: {test_loss:.4f}\")\n","print(f\"Jaccard Index: {test_jaccard:.4f}\")\n","print(f\"Dice Coefficient: {test_dice:.4f}\")\n","print(f\"Precision: {test_precision:.4f}\")\n","print(f\"Recall: {test_recall:.4f}\")\n","print(f\"Accuracy: {test_accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bY2qLAws5jCM"},"outputs":[],"source":["# --- 5. Evaluation and Visualization ---\n","\n","def plot_history(history, title):\n","    \"\"\"\n","    Plots the training and validation loss and Dice Coefficient over epochs.\n","    \"\"\"\n","    if history is None:\n","        print(f\"No history to plot for {title}.\")\n","        return\n","\n","    plt.figure(figsize=(12, 5))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['loss'], label='Train Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title(f'{title} - Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['dice_coefficient'], label='Train Dice Coeff')\n","    plt.plot(history.history['val_dice_coefficient'], label='Validation Dice Coeff')\n","    plt.title(f'{title} - Dice Coefficient')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Dice Coeff')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmVgRshZ5sLr"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","# IMPORTANT: Ensure your 'my_trained_model' (your main model object),\n","# X_test, and y_test are defined and loaded before running this.\n","\n","# Example for dummy data/model if you're just testing the visualization:\n","if 'my_trained_model' not in locals():\n","    print(\"WARNING: 'my_trained_model' not found. Creating a DUMMY model for visualization testing.\")\n","    input_shape = (128, 128, 3) # Adjust to your actual input image shape\n","    dummy_inputs = tf.keras.layers.Input(input_shape)\n","    dummy_conv = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(dummy_inputs)\n","    my_trained_model = tf.keras.Model(inputs=dummy_inputs, outputs=dummy_conv)\n","\n","if 'X_test' not in locals() or not isinstance(X_test, np.ndarray) or X_test.size == 0:\n","    print(\"WARNING: X_test/y_test not found. Creating DUMMY data for visualization testing.\")\n","    X_test = np.random.rand(10, 128, 128, 3).astype(np.float32) # Adjust shape as needed\n","    y_test = np.random.randint(0, 2, size=(10, 128, 128, 1)).astype(np.float32) # Adjust shape as needed\n","\n","\n","def visualize_predictions(main_model_object, model1_path, model2_path, model3_path, model4_path,\n","                          X_set, y_set, num_samples=5):\n","    \"\"\"\n","    Visualizes original image, ground truth, main model's prediction, and\n","    predictions from four other specified models in a grid.\n","\n","    Args:\n","        main_model_object (tf.keras.Model): Your primary Keras model object (passed directly).\n","        model1_path (str): Path to the first comparison model (FCRBUnet).\n","        model2_path (str): Path to the second comparison model (ECAUnet).\n","        model3_path (str): Path to the third comparison model (Auto_ReUnet).\n","        model4_path (str): Path to the fourth comparison model (Dual_CNN).\n","        X_set (np.array): Input images for prediction.\n","        y_set (np.array): Ground truth masks.\n","        num_samples (int): Number of samples (rows) to display.\n","    \"\"\"\n","    if len(X_set) == 0:\n","        print(f\"No data to visualize predictions.\")\n","        return\n","\n","    num_samples_to_display = min(num_samples, len(X_set))\n","\n","    # --- Load Additional Models (from .h5 files) ---\n","    loaded_additional_models = []\n","    additional_model_paths = [model1_path, model2_path, model3_path, model4_path]\n","\n","    # Define intended display names for the additional models\n","    additional_model_display_names = [\"FCRBUnet\", \"ECAUnet\", \"Auto_ReUnet\", \"Dual_CNN\"]\n","\n","    # This list will store the names of only the models that SUCCESSFULLY load\n","    actual_loaded_additional_names = []\n","\n","    print(\"\\n--- Attempting to load additional models ---\")\n","    for i, path in enumerate(additional_model_paths):\n","        display_name = additional_model_display_names[i]\n","        try:\n","            # --- CRITICAL CHECK FOR FILE TYPE ---\n","            if not os.path.exists(path):\n","                print(f\"ERROR: File for {display_name} NOT FOUND at '{path}'. Skipping this model.\")\n","                continue\n","            if path.endswith('.ipynb'): # This was the specific issue for model3_path\n","                print(f\"ERROR: {display_name} path '{path}' is a .ipynb file. Keras cannot load models from notebooks. Please provide the .h5 model file path. Skipping this model.\")\n","                continue\n","\n","            model_loaded = tf.keras.models.load_model(path)\n","            loaded_additional_models.append(model_loaded)\n","            actual_loaded_additional_names.append(display_name) # Add name only if loaded\n","            print(f\"SUCCESS: Loaded {display_name} from '{path}'.\")\n","        except Exception as e:\n","            print(f\"ERROR loading {display_name} from '{path}': {e}. Skipping this model.\")\n","            # If an error occurs (e.g., corrupted file, wrong format), it's caught here.\n","\n","    print(\"--- Finished loading additional models ---\\n\")\n","\n","    # --- Make predictions ---\n","    # Use the directly passed main_model_object\n","    predictions_main = main_model_object.predict(X_set[:num_samples_to_display])\n","\n","    predictions_additional = []\n","    for model_obj in loaded_additional_models:\n","        predictions_additional.append(model_obj.predict(X_set[:num_samples_to_display]))\n","\n","    # --- Setup Plotting ---\n","    # Calculate total columns based on what ACTUALLY loaded\n","    total_columns = 2 + 1 + len(loaded_additional_models)\n","\n","    # Define column titles for clarity, matching the order of plots\n","    column_titles = [\"Original\", \"Ground Truth\", \"My Model\"] + actual_loaded_additional_names\n","\n","    print(f\"Generating plot with {num_samples_to_display} rows and {total_columns} columns.\")\n","    plt.figure(figsize=(total_columns * 3, num_samples_to_display * 3)) # Adjust figure size\n","\n","    for i in range(num_samples_to_display): # Loop for each sample (row)\n","        # 1. Original Image (Column 1)\n","        plt.subplot(num_samples_to_display, total_columns, i * total_columns + 1)\n","        plt.imshow(X_set[i])\n","        plt.axis('off')\n","        if i == 0: plt.title(column_titles[0], fontsize=10) # Title only for the first row\n","\n","        # 2. True Mask (Column 2)\n","        plt.subplot(num_samples_to_display, total_columns, i * total_columns + 2)\n","        plt.imshow(y_set[i].squeeze(), cmap='gray')\n","        plt.axis('off')\n","        if i == 0: plt.title(column_titles[1], fontsize=10)\n","\n","        # 3. My Model Predicted Mask (Column 3)\n","        plt.subplot(num_samples_to_display, total_columns, i * total_columns + 3)\n","        predicted_mask_main = (predictions_main[i].squeeze() > 0.5).astype(np.float32)\n","        plt.imshow(predicted_mask_main, cmap='gray')\n","        plt.axis('off')\n","        if i == 0: plt.title(column_titles[2], fontsize=10)\n","\n","        # 4. Additional Models Predicted Masks (Columns 4 onwards)\n","        for model_idx, preds_for_model in enumerate(predictions_additional):\n","            current_col_idx = i * total_columns + (3 + 1 + model_idx)\n","\n","            plt.subplot(num_samples_to_display, total_columns, current_col_idx)\n","            predicted_mask = (preds_for_model[i].squeeze() > 0.5).astype(np.float32)\n","            plt.imshow(predicted_mask, cmap='gray')\n","            plt.axis('off')\n","            if i == 0: plt.title(column_titles[3 + model_idx], fontsize=10)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","# --- How to use this function ---\n","\n","# 1. Define your main model object (e.g., 'my_trained_model' after training)\n","#    (Example dummy model provided at the top if needed for testing this script itself)\n","\n","# 2. Define the paths to your 4 additional models (.h5 files)\n","model1_path = '/content/drive/MyDrive/Colab/PHD/Cerebellar/Methods/FCRBUnet_model.h5'\n","model2_path = '/content/drive/MyDrive/Colab/PHD/Cerebellar/Methods/ECAUnet_model.h5'\n","model3_path = '/content/drive/MyDrive/Colab/PHD/Cerebellar/Methods/Aut_ReUnet_model.h5'\n","model4_path = '/content/drive/MyDrive/Colab/PHD/Cerebellar/Methods/Dual_CNN_model.h5'\n","\n","# 3. Ensure your X_test and y_test data are loaded and available\n","#    (Example dummy data provided at the top if needed for testing this script itself)\n","\n","print(\"--- Starting Visualization Script ---\")\n","visualize_predictions(\n","    main_model_object=model, # Pass your actual Keras model object here\n","    model1_path=model1_path,\n","    model2_path=model2_path,\n","    model3_path=model3_path,\n","    model4_path=model4_path,\n","    X_set=X_test,\n","    y_set=y_test,\n","    num_samples=5\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xAX60oSv2IEC"},"outputs":[],"source":["# --- NEW: Test-Time Augmentation (TTA) Prediction Function ---\n","def predict_with_tta(model, image, tta_transforms):\n","    predictions = []\n","\n","    # Original prediction\n","    original_pred = model.predict(np.expand_dims(image, axis=0), verbose=0)[0]\n","    predictions.append(original_pred)\n","\n","    for transform_func, inverse_transform_func in tta_transforms:\n","        # Apply transform to image\n","        aug_image = transform_func(image)\n","        # Predict on augmented image\n","        aug_pred = model.predict(np.expand_dims(aug_image, axis=0), verbose=0)[0]\n","        # Inverse transform prediction\n","        inverse_pred = inverse_transform_func(aug_pred)\n","        predictions.append(inverse_pred)\n","\n","    # Average predictions from all augmented versions\n","    avg_prediction = np.mean(predictions, axis=0)\n","    return avg_prediction\n","\n","# Define simple TTA transforms for demonstration\n","def flip_lr(img_or_mask): return np.fliplr(img_or_mask).astype(np.float32)\n","def flip_ud(img_or_mask): return np.flipud(img_or_mask).astype(np.float32)\n","def rotate_90(img_or_mask): return np.rot90(img_or_mask, k=1).astype(np.float32)\n","def rotate_270(img_or_mask): return np.rot90(img_or_mask, k=-1).astype(np.float32) # Inverse of rotate_90\n","\n","TTA_TRANSFORMS = [\n","    (flip_lr, flip_lr), # Left-Right flip\n","    (flip_ud, flip_ud), # Up-Down flip\n","    (rotate_90, rotate_270), # Rotate 90 degrees clockwise\n","    (rotate_270, rotate_90), # Rotate 90 degrees counter-clockwise\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43KVCycx5jE8"},"outputs":[],"source":["plot_history(history_decoder, \"Decoder Training\")\n","plot_history(history_full, \"Full Fine-tuning\")\n","\n","if 'history_pseudo_labeling' in locals() and history_pseudo_labeling is not None:\n","    plot_history(history_pseudo_labeling, \"Pseudo-labeling Fine-tuning\")\n","\n","\n","print(\"\\nVisualizing predictions on validation set...\")\n","visualize_predictions(\n","    main_model_object=model,\n","    model1_path=model1_path,\n","    model2_path=model2_path,\n","    model3_path=model3_path,\n","    model4_path=model4_path,\n","    X_set=X_val,\n","    y_set=y_val,\n","    num_samples=5\n",")\n","\n","\n","print(\"\\nVisualizing predictions on test set (without TTA)...\")\n","# Visualize predictions for 5 random samples from the test set (without TTA).\n","visualize_predictions(\n","    main_model_object=model,\n","    model1_path=model1_path,\n","    model2_path=model2_path,\n","    model3_path=model3_path,\n","    model4_path=model4_path,\n","    X_set=X_test,\n","    y_set=y_test,\n","    num_samples=5\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAqR8blpmvGo"},"outputs":[],"source":["\n","# Final Evaluation on Test Set with Test-Time Augmentation (TTA) ---\n","print(\"\\n--- Final Evaluation on Test Set with Test-Time Augmentation (TTA) ---\")\n","\n","if len(X_test) > 0:\n","    tta_predictions_list = []\n","    print(f\"Applying TTA to {len(X_test)} test images...\")\n","    for i, img in enumerate(X_test):\n","        tta_pred = predict_with_tta(model, img, TTA_TRANSFORMS)\n","        tta_predictions_list.append(tta_pred)\n","        if (i + 1) % 10 == 0 or (i + 1) == len(X_test):\n","            clear_output(wait=True)\n","            print(f\"Processed {i + 1}/{len(X_test)} test images with TTA.\")\n","\n","    tta_predictions = np.array(tta_predictions_list)\n","\n","    # Calculate metrics with TTA predictions\n","    tta_dice_scores = []\n","    for i in range(len(X_test)):\n","        # Binarize TTA prediction for Dice calculation\n","        bin_tta_pred = (tta_predictions[i] > 0.5).astype(np.float32)\n","        tta_dice_scores.append(dice_coeff(y_test[i], bin_tta_pred).numpy())\n","\n","    overall_tta_dice = np.mean(tta_dice_scores)\n","\n","    print(f\"\\nOverall Test Dice Coefficient (with TTA): {overall_tta_dice:.4f}\")\n","\n","    # Let's also evaluate without TTA for comparison\n","    non_tta_test_loss, non_tta_test_dice, non_tta_test_accuracy = model.evaluate(tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE))\n","    print(f\"Overall Test Dice Coefficient (without TTA): {non_tta_test_dice:.4f}\")\n","    print(f\"Overall Test Loss (without TTA): {non_tta_test_loss:.4f}\")\n","    print(f\"Overall Test Accuracy (without TTA): {non_tta_test_accuracy:.4f}\")\n","\n","\n","    # --- Visualizing TTA predictions on Test Set ---\n","    print(\"\\nVisualizing predictions on test set (with TTA)...\")\n","    # Take the first 5 predictions with TTA for visualization\n","    tta_visual_preds = []\n","    for i in range(5):\n","        if i < len(X_test):\n","            tta_visual_preds.append((tta_predictions[i] > 0.5).astype(np.float32))\n","\n","    if :\n","        plt.figure(figsize=(15, 5 * 3)) # Adjust figure size dynamically\n","        for i in range(len(tta_visual_preds)):\n","            plt.subplot(len(tta_visual_preds), 3, i*3 + 1)\n","            plt.imshow(X_test[i])\n","            plt.title(f'Test Original Image {i+1}')\n","            plt.axis('off')\n","\n","            plt.subplot(len(tta_visual_preds), 3, i*3 + 2)\n","            plt.imshow(y_test[i].squeeze(), cmap='gray')\n","            plt.title(f'Test True Mask {i+1}')\n","            plt.axis('off')\n","\n","            plt.subplot(len(tta_visual_preds), 3, i*3 + 3)\n","            plt.imshow(tta_visual_preds[i].squeeze(), cmap='gray')\n","            plt.title(f'Test Predicted Mask (TTA) {i+1}')\n","            plt.axis('off')\n","        plt.tight_layout()\n","        plt.show()\n","\n","else:\n","    print(\"No test data available for evaluation.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMU9d4fK5jHt"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","\n","def visualize_augmentation_examples(original_image, original_mask):\n","\n","    if original_image is None or original_mask is None:\n","        print(\"Original image or mask is None. Cannot visualize augmentations.\")\n","        return\n","\n","    # Get augmented images and masks. We will ONLY use the images for plotting.\n","    augmented_images_list, _, denoised_original_image = apply_paper_augmentation(original_image, original_mask)\n","\n","    # --- Collect all images to display ---\n","    # This list will contain the 10 images in the desired order for the 2x5 grid:\n","    # Original, Denoised, then the 8 augmented images from your function.\n","    all_images_to_display = [original_image, denoised_original_image] + augmented_images_list\n","\n","    # Define the number of images we expect to display\n","    num_total_images = len(all_images_to_display) # Should be 10 (1 original + 1 denoised + 8 augmented)\n","\n","    # --- Define Grid Size ---\n","    num_cols = 5\n","    num_rows = math.ceil(num_total_images / num_cols) # For 10 images and 5 columns, this will be 2.\n","\n","    # --- Define Titles for each image in the grid ---\n","    # These titles should match the order in 'all_images_to_display'.\n","    # Adjust these labels to be more specific to your augmentations if needed.\n","    image_titles = [\n","        'Original Image',\n","        'Denoised Image',\n","        'Augmented (Type 1)',      # Replace with your actual augmentation names (e.g., Dilation 3x3)\n","        'Augmented (Type 2)',\n","        'Augmented (Type 3)',\n","        'Augmented (Type 4)',\n","        'Augmented (Type 5)',\n","        'Augmented (Type 6)',\n","        'Augmented (Type 7)',\n","        'Augmented (Type 8)'\n","    ]\n","    # Ensure titles list matches the actual number of images if `augmented_images_list`\n","    # happens to return a number different from 8.\n","    image_titles = image_titles[:num_total_images]\n","\n","    # --- Create Figure and Subplots ---\n","    # Adjust figsize: width = num_cols * scaling_factor, height = num_rows * scaling_factor\n","    # The '3.5' here is a scaling factor; adjust it to make images bigger or smaller on the plot.\n","    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 3.5, num_rows * 3.5))\n","    axes = axes.flatten() # Flatten the 2D array of axes for easy 1D indexing\n","\n","    # Set a main title for the entire figure\n","    fig.suptitle('Data Augmentation Examples (Images Only for Article)', fontsize=16, y=1.02)\n","\n","    # --- Plot Each Image ---\n","    for i in range(num_total_images):\n","        if i < len(axes): # Safety check to prevent errors if num_total_images somehow exceeds subplot count\n","            axes[i].imshow(all_images_to_display[i])\n","            axes[i].set_title(image_titles[i], fontsize=9) # Apply specific title\n","            axes[i].axis('off') # Remove axes for a clean, article-ready look\n","        # No 'else' block needed, as we hide remaining subplots below\n","\n","    # --- Hide any remaining empty subplots ---\n","    # This loop ensures that if num_total_images is less than num_rows * num_cols (e.g., 9 images in 2x5 grid),\n","    # the extra empty subplots are hidden.\n","    for i in range(num_total_images, len(axes)):\n","        axes[i].set_visible(False)\n","\n","    # --- Minimize space between subplots and show plot ---\n","    # plt.tight_layout() automatically adjusts subplot parameters for a tight layout.\n","    # 'rect' parameter adjusts the bounding box for the subplots, leaving space for the suptitle.\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n","    plt.show()\n","\n","\n","# --- Example Usage (Using your existing variables X_train, y_train) ---\n","\n","# IMPORTANT: Ensure your X_train and y_train are loaded and available\n","# (e.g., X_train = np.load('path/to/X_train.npy'), y_train = np.load('path/to/y_train.npy'))\n","\n","if 'X_train' in locals() and len(X_train) > 0:\n","    sample_index = np.random.randint(0, len(X_train))\n","    sample_image = X_train[sample_index]\n","    sample_mask = y_train[sample_index]\n","\n","    print(f\"\\n--- Visualizing Data Augmentation (Images Only) for Sample {sample_index} ---\")\n","    visualize_augmentation_examples(sample_image, sample_mask)\n","else:\n","    print(\"\\nError: X_train not found or is empty. Please ensure X_train and y_train are loaded.\")\n","    print(\"Example: X_train = np.random.rand(10, 128, 128, 3).astype(np.float32)\")\n","    print(\"         y_train = np.random.randint(0, 2, size=(10, 128, 128, 1)).astype(np.float32)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cpJYSXY5jMy"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JnqBI3uE5jQH"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP0m+HryajEuGKAtuMoa7Fa"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}